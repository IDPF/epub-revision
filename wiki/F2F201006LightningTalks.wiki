#summary Slides/Abstracts of the June 2010 F2F lightning talks

<wiki:toc max_depth="3" />

= Accessibility =
==Accessibility and EPUB==
Lightning Talk 
George Kerscher and Kenny  Johar
===1. Who Wants Access to eBooks===
 * Blind and low vision (.3.3 of 1%)
 * Dyslexic ( guessing 2%)
 * Learning Disabled (guessing 6%)
 * not all LD require accessibility techniques)
 * Physically disabled, such as quadriplegics 
 * Cognitively disabled

=== 2. Legal Considerations ===
 * United Nations Convention on the Rights of Persons with Disabilities
 * Laws in countries, such as 508 and 504 in the USA
 * Department of Justice (DOJ)  and settlements
 * Voluntary refusals to not use inaccessible technologies

=== 3.  The Handshake between semantically Rich, Structured  content and reading systems ===
 * Content must be accessible AND  Reading System UI must be accessible
 * Websites for purchasing must be accessible (W3C/WAI Guidelines)
 * Semantically rich  structured content is essential
 * Intelligent reading Systems use the semantics 

=== 4. Techniques ===
 * Structure the content using semantics
 * Identify content based on what it is, e.g. a paragraph is not a heading!
 * Order the content for correct reading order, i.e. the way it appears in a DOM
 * Images, flow charts, etc. require short and long descriptions
 * Video must support captioning and descriptive audio channel
 * Interactivity must be accessible, which is a big question

== Speech Synthesizer support ==
Markus Gylling

 * An increasing number of reading devices ship with built-in TTS
 * For the print disabled in particular, this is a crucial feature
 * But good (read: low rate of mispronunciation, near-correct prosody (stress, intonation) is a general device usability concern

===Problems ===
The use of TTS within the DAISY realm over the past decade has identified the following core problems:
 * While TTS quality has improved, the quality varies dramatically between languages (the bigger the language, the larger the market for TTS vendors)
 * For academic and specific-domain content, most TTS's fail miserably (too many terms not covered by hardwired lexicon). For professionals and students, this means that consuming content using TTS is painful at best and impossible at worst.

=== Requirements ===
 * A way to link to publication and/or document-wide pronunciation lexica
 * A way to specify atomic pronunciation and prosody rules inline (lexicon-provided generalizations are not sufficient)

=== Solutions ===
Existing languages that we can reuse:
==== SSML ====
 * [http://www.w3.org/TR/pronunciation-lexicon/ PLS] defines a lexicon document type for pronunciation instructions
 * [http://www.w3.org/TR/speech-synthesis11/ SSML 1.1] defines a set of elements that can be adapted for inline usage. (see also Z3986-AI which defines an [http://www.daisy.org/z3986/2011/schema/mod/ssml-phoneme-attrib.rng attribute-axis-only adaption] for SSML-based pronunciation instructions).

... note: SSML is partially or fully supported by TTS engines such as [http://cepstral.com/cgi-bin/support?page=ssml cepstral], [http://vhost.oddcast.com/vhost_minisite/support/ssml/ssml.php?engine=1 AT&amp;T], [http://vhost.oddcast.com/vhost_minisite/support/ssml/ssml.php?engine=2 Loquendo], [http://www.neospeech.com/ neospeech], and more.

==== CSS3 ====
 * http://www.w3.org/TR/css3-speech/